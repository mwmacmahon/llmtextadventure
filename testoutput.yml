app_name: chat
config:
  interface_config:
    interface_mode: Default-CLI
  interface_type: cli
  llm_config:
    backend_config:
      model_settings:
        context_limit: 2000
        model: gpt-3.5-turbo
      name_of_model: gpt-3.5-turbo
    backend_config_type: OpenAI
    generation_config:
      max_tokens: 500
      openai_frequency_penalty: 0.0
      openai_n: 1.0
      openai_presence_penalty: 0.0
      openai_stop: []
      temperature: 1.0
      top_p: 1.0
    generation_preset: default
  parsing_config:
    parsing_functions: []
  transformation_config:
    transformation_functions:
    - name: cleanup_whitespace
state:
  chat_history:
  - content: test
    num_tokens: 1
    role: user
    timestamp: '2023-12-24T18:27:22.644132Z'
    truncated: false
  - content: What would you like to test?
    num_tokens: 7
    role: assistant
    timestamp: '2023-12-24T18:27:23.665122Z'
    truncated: false
  hidden_data: null
  raw_history: []
  situational_flags: null
