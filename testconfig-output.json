{
    "config": {
        "llm_config": {
            "backend_config_type": "HFTGI",
            "backend_config": {
                "name_of_model": "llama3",
                "hftgi_settings": {
                    "model": "llama2"
                }
            },
            "generation_preset": "default",
            "generation_config": {
                "max_tokens": 500,
                "temperature": 0.5,
                "top_p": null
            }
        },
        "transformation_config": {
            "transformation_functions": []
        },
        "parsing_config": {
            "parsing_functions": []
        }
    },
    "state": {
        "history": [],
        "raw_history": [],
        "hidden_data": null,
        "situational_flags": null
    },
    "app_name": "Chat"
}